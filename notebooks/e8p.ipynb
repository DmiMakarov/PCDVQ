{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7748e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 1: 112 roots\n",
      "(-0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5)\n",
      "(-0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 0.5, 0.5)\n",
      "(-0.5, -0.5, -0.5, -0.5, -0.5, 0.5, -0.5, 0.5)\n",
      "(-0.5, -0.5, -0.5, -0.5, -0.5, 0.5, 0.5, -0.5)\n",
      "(-0.5, -0.5, -0.5, -0.5, 0.5, -0.5, -0.5, 0.5)\n",
      "(-0.5, -0.5, -0.5, -0.5, 0.5, -0.5, 0.5, -0.5)\n",
      "(-0.5, -0.5, -0.5, -0.5, 0.5, 0.5, -0.5, -0.5)\n",
      "(-0.5, -0.5, -0.5, -0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "(-0.5, -0.5, -0.5, 0.5, -0.5, -0.5, -0.5, 0.5)\n",
      "(-0.5, -0.5, -0.5, 0.5, -0.5, -0.5, 0.5, -0.5)\n",
      "(-0.5, -0.5, -0.5, 0.5, -0.5, 0.5, -0.5, -0.5)\n",
      "(-0.5, -0.5, -0.5, 0.5, -0.5, 0.5, 0.5, 0.5)\n",
      "(-0.5, -0.5, -0.5, 0.5, 0.5, -0.5, -0.5, -0.5)\n",
      "(-0.5, -0.5, -0.5, 0.5, 0.5, -0.5, 0.5, 0.5)\n",
      "(-0.5, -0.5, -0.5, 0.5, 0.5, 0.5, -0.5, 0.5)\n",
      "(-0.5, -0.5, -0.5, 0.5, 0.5, 0.5, 0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, -0.5, -0.5, -0.5, -0.5, 0.5)\n",
      "(-0.5, -0.5, 0.5, -0.5, -0.5, -0.5, 0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, -0.5, -0.5, 0.5, -0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, -0.5, -0.5, 0.5, 0.5, 0.5)\n",
      "(-0.5, -0.5, 0.5, -0.5, 0.5, -0.5, -0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, 0.5)\n",
      "(-0.5, -0.5, 0.5, -0.5, 0.5, 0.5, -0.5, 0.5)\n",
      "(-0.5, -0.5, 0.5, -0.5, 0.5, 0.5, 0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, 0.5, -0.5, -0.5, -0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, 0.5, -0.5, -0.5, 0.5, 0.5)\n",
      "(-0.5, -0.5, 0.5, 0.5, -0.5, 0.5, -0.5, 0.5)\n",
      "(-0.5, -0.5, 0.5, 0.5, -0.5, 0.5, 0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, 0.5, 0.5, -0.5, -0.5, 0.5)\n",
      "(-0.5, -0.5, 0.5, 0.5, 0.5, -0.5, 0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, 0.5, 0.5, 0.5, -0.5, -0.5)\n",
      "(-0.5, -0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 0.5)\n",
      "(-0.5, 0.5, -0.5, -0.5, -0.5, -0.5, 0.5, -0.5)\n",
      "(-0.5, 0.5, -0.5, -0.5, -0.5, 0.5, -0.5, -0.5)\n",
      "(-0.5, 0.5, -0.5, -0.5, -0.5, 0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, -0.5, -0.5, 0.5, -0.5, -0.5, -0.5)\n",
      "(-0.5, 0.5, -0.5, -0.5, 0.5, -0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, -0.5, -0.5, 0.5, 0.5, -0.5, 0.5)\n",
      "(-0.5, 0.5, -0.5, -0.5, 0.5, 0.5, 0.5, -0.5)\n",
      "(-0.5, 0.5, -0.5, 0.5, -0.5, -0.5, -0.5, -0.5)\n",
      "(-0.5, 0.5, -0.5, 0.5, -0.5, -0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5)\n",
      "(-0.5, 0.5, -0.5, 0.5, -0.5, 0.5, 0.5, -0.5)\n",
      "(-0.5, 0.5, -0.5, 0.5, 0.5, -0.5, -0.5, 0.5)\n",
      "(-0.5, 0.5, -0.5, 0.5, 0.5, -0.5, 0.5, -0.5)\n",
      "(-0.5, 0.5, -0.5, 0.5, 0.5, 0.5, -0.5, -0.5)\n",
      "(-0.5, 0.5, -0.5, 0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, -0.5, -0.5, -0.5, -0.5, -0.5)\n",
      "(-0.5, 0.5, 0.5, -0.5, -0.5, -0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, -0.5, -0.5, 0.5, -0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, -0.5, -0.5, 0.5, 0.5, -0.5)\n",
      "(-0.5, 0.5, 0.5, -0.5, 0.5, -0.5, -0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5)\n",
      "(-0.5, 0.5, 0.5, -0.5, 0.5, 0.5, -0.5, -0.5)\n",
      "(-0.5, 0.5, 0.5, -0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, 0.5, -0.5, -0.5, -0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, 0.5, -0.5, -0.5, 0.5, -0.5)\n",
      "(-0.5, 0.5, 0.5, 0.5, -0.5, 0.5, -0.5, -0.5)\n",
      "(-0.5, 0.5, 0.5, 0.5, -0.5, 0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, 0.5, 0.5, -0.5, -0.5, -0.5)\n",
      "(-0.5, 0.5, 0.5, 0.5, 0.5, -0.5, 0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, 0.5, 0.5, 0.5, -0.5, 0.5)\n",
      "(-0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 0.5)\n",
      "(0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, -0.5, -0.5, 0.5, -0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, -0.5, -0.5, 0.5, 0.5, 0.5)\n",
      "(0.5, -0.5, -0.5, -0.5, 0.5, -0.5, -0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, -0.5, 0.5, -0.5, 0.5, 0.5)\n",
      "(0.5, -0.5, -0.5, -0.5, 0.5, 0.5, -0.5, 0.5)\n",
      "(0.5, -0.5, -0.5, -0.5, 0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, 0.5, -0.5, -0.5, -0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, 0.5, -0.5, -0.5, 0.5, 0.5)\n",
      "(0.5, -0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5)\n",
      "(0.5, -0.5, -0.5, 0.5, -0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, 0.5, 0.5, -0.5, -0.5, 0.5)\n",
      "(0.5, -0.5, -0.5, 0.5, 0.5, -0.5, 0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, 0.5, 0.5, 0.5, -0.5, -0.5)\n",
      "(0.5, -0.5, -0.5, 0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, -0.5, -0.5, -0.5, -0.5, -0.5)\n",
      "(0.5, -0.5, 0.5, -0.5, -0.5, -0.5, 0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, -0.5, -0.5, 0.5, -0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, -0.5, -0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, -0.5, 0.5, -0.5, 0.5, -0.5, -0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5)\n",
      "(0.5, -0.5, 0.5, -0.5, 0.5, 0.5, -0.5, -0.5)\n",
      "(0.5, -0.5, 0.5, -0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, 0.5, -0.5, -0.5, -0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, 0.5, -0.5, -0.5, 0.5, -0.5)\n",
      "(0.5, -0.5, 0.5, 0.5, -0.5, 0.5, -0.5, -0.5)\n",
      "(0.5, -0.5, 0.5, 0.5, -0.5, 0.5, 0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, 0.5, 0.5, -0.5, -0.5, -0.5)\n",
      "(0.5, -0.5, 0.5, 0.5, 0.5, -0.5, 0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, 0.5, 0.5, 0.5, -0.5, 0.5)\n",
      "(0.5, -0.5, 0.5, 0.5, 0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5)\n",
      "(0.5, 0.5, -0.5, -0.5, -0.5, -0.5, 0.5, 0.5)\n",
      "(0.5, 0.5, -0.5, -0.5, -0.5, 0.5, -0.5, 0.5)\n",
      "(0.5, 0.5, -0.5, -0.5, -0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, -0.5, -0.5, 0.5, -0.5, -0.5, 0.5)\n",
      "(0.5, 0.5, -0.5, -0.5, 0.5, -0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, -0.5, -0.5, 0.5, 0.5, -0.5, -0.5)\n",
      "(0.5, 0.5, -0.5, -0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "(0.5, 0.5, -0.5, 0.5, -0.5, -0.5, -0.5, 0.5)\n",
      "(0.5, 0.5, -0.5, 0.5, -0.5, -0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, -0.5, 0.5, -0.5, 0.5, -0.5, -0.5)\n",
      "(0.5, 0.5, -0.5, 0.5, -0.5, 0.5, 0.5, 0.5)\n",
      "(0.5, 0.5, -0.5, 0.5, 0.5, -0.5, -0.5, -0.5)\n",
      "(0.5, 0.5, -0.5, 0.5, 0.5, -0.5, 0.5, 0.5)\n",
      "(0.5, 0.5, -0.5, 0.5, 0.5, 0.5, -0.5, 0.5)\n",
      "(0.5, 0.5, -0.5, 0.5, 0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, -0.5, -0.5, -0.5, -0.5, 0.5)\n",
      "(0.5, 0.5, 0.5, -0.5, -0.5, -0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, -0.5, -0.5, 0.5, -0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, -0.5, -0.5, 0.5, 0.5, 0.5)\n",
      "(0.5, 0.5, 0.5, -0.5, 0.5, -0.5, -0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, -0.5, 0.5, -0.5, 0.5, 0.5)\n",
      "(0.5, 0.5, 0.5, -0.5, 0.5, 0.5, -0.5, 0.5)\n",
      "(0.5, 0.5, 0.5, -0.5, 0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, 0.5, -0.5, -0.5, -0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, 0.5, -0.5, -0.5, 0.5, 0.5)\n",
      "(0.5, 0.5, 0.5, 0.5, -0.5, 0.5, -0.5, 0.5)\n",
      "(0.5, 0.5, 0.5, 0.5, -0.5, 0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, 0.5, 0.5, -0.5, -0.5, 0.5)\n",
      "(0.5, 0.5, 0.5, 0.5, 0.5, -0.5, 0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, -0.5, -0.5)\n",
      "(0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5)\n",
      "Type 2: 240 roots\n",
      "torch.Size([240, 8])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from itertools import product\n",
    "\n",
    "def generate_e8_roots():\n",
    "        # Standard way to generate the 240 E8 roots in 8D\n",
    "        roots = []\n",
    "\n",
    "        # Type 1: ±e_i ± e_j (i < j)\n",
    "        for i in range(8):\n",
    "            for j in range(i + 1, 8):\n",
    "                for signs in [(1, 1), (1, -1), (-1, 1), (-1, -1)]:\n",
    "                    v = torch.zeros(8)\n",
    "                    v[i] = signs[0]\n",
    "                    v[j] = signs[1]\n",
    "                    roots.append(v)\n",
    "\n",
    "        print(f\"Type 1: {len(roots)} roots\")\n",
    "\n",
    "        # Type 2: (±1/2, ±1/2, ..., ±1/2) with even number of + signs\n",
    "        for signs in product([-0.5, 0.5], repeat=8):\n",
    "            if sum(s > 0 for s in signs) % 2 == 0:  # even number of +1/2\n",
    "                print(signs)\n",
    "                v = torch.tensor(signs)\n",
    "                roots.append(v)\n",
    "\n",
    "        print(f\"Type 2: {len(roots)} roots\")\n",
    "\n",
    "        roots = torch.stack(roots)\n",
    "        # Normalize to unit length (all have norm sqrt(2) actually)\n",
    "        #roots = roots / roots.norm(dim=1, keepdim=True)\n",
    "        # Remove duplicates (there are exactly 240 unique up to sign)\n",
    "        roots = torch.unique(roots, dim=0)\n",
    "        assert roots.shape[0] == 240\n",
    "\n",
    "        return roots  # (240, 8)\n",
    "\n",
    "\n",
    "e8_roots = generate_e8_roots()\n",
    "print(e8_roots.shape)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b12146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5000, -0.5000, -0.5000,  ..., -0.5000,  0.5000,  0.5000],\n",
       "        [-0.5000, -0.5000, -0.5000,  ...,  0.5000, -0.5000,  0.5000],\n",
       "        [-0.5000, -0.5000, -0.5000,  ...,  0.5000,  0.5000, -0.5000],\n",
       "        ...,\n",
       "        [ 0.5000,  0.5000,  0.5000,  ..., -0.5000,  0.5000, -0.5000],\n",
       "        [ 0.5000,  0.5000,  0.5000,  ...,  0.5000, -0.5000, -0.5000],\n",
       "        [ 0.5000,  0.5000,  0.5000,  ...,  0.5000,  0.5000,  0.5000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (e8_roots == 0.5).any(dim=1)   # rows where at least one entry == 0.5\n",
    "e8_roots[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc1630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e8_roots == 1/2) | (e8_roots == -1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c275103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_d8_half_vectors(max_sq_norm: float = 10.0) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    vectors = []\n",
    "\n",
    "    # From (k_i + 1/2)^2 < 10 we get |k_i + 1/2| < sqrt(10) ~ 3.16,\n",
    "    # so k_i must lie in {-3, -2, -1, 0, 1, 2}.\n",
    "    for ks in tqdm(product([0.5, 1.5, 2.5], repeat=8)):\n",
    "        vec = torch.tensor(ks)\n",
    "\n",
    "        if (vec < 0).any() or vec.dot(vec) > max_sq_norm:\n",
    "            continue\n",
    "\n",
    "        vectors.append(vec)\n",
    "\n",
    "    if not vectors:\n",
    "        raise RuntimeError(\"No D8 half-integer vectors found; check constraints.\")\n",
    "\n",
    "    vectors = torch.stack(vectors, dim=0)\n",
    "    # Remove any possible duplicates (should not occur, but this is safe).\n",
    "    vectors = torch.unique(vectors, dim=0)\n",
    "\n",
    "    # QUIP#/VQ construction expects exactly 227 such vectors.\n",
    "    #assert vectors.shape[0] == 227, f\"Expected 227 vectors, got {vectors.shape[0]}\"\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d0e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6561it [00:00, 124852.90it/s]\n"
     ]
    }
   ],
   "source": [
    "d8 = generate_d8_half_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b452eb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([227, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7961779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_12(d8_half_vectors:torch.Tensor)->torch.Tensor:\n",
    "    \"\"\"Append 12 to the end of the vector.\"\"\"\n",
    "    additional = torch.tensor([[3, 1, 1, 1, 3, 3, 3, 3], [1, 3, 1, 1, 3, 3, 3, 3], [1, 1, 3, 1, 3, 3, 3, 3],\n",
    "                               [1, 1, 1, 3, 3, 3, 3, 3], [3, 3, 3, 1, 3, 3, 1, 1], [3, 3, 3, 1, 3, 1, 3, 1],\n",
    "                               [3, 3, 3, 1, 1, 3, 3, 1], [3, 3, 3, 1, 3, 1, 1, 3], [3, 3, 3, 1, 1, 3, 1, 3],\n",
    "                               [3, 3, 3, 1, 1, 1, 3, 3], [3, 3, 1, 3, 3, 3, 1, 1], [3, 3, 1, 3, 3, 1, 3, 1],\n",
    "                               [3, 3, 1, 3, 1, 3, 3, 1], [3, 3, 1, 3, 3, 1, 1, 3], [3, 3, 1, 3, 1, 3, 1, 3],\n",
    "                               [3, 3, 1, 3, 1, 1, 3, 3], [3, 1, 3, 3, 3, 3, 1, 1], [3, 1, 3, 3, 3, 1, 3, 1],\n",
    "                               [3, 1, 3, 3, 1, 3, 3, 1], [3, 1, 3, 3, 3, 1, 1, 3], [3, 1, 3, 3, 1, 3, 1, 3],\n",
    "                               [1, 3, 3, 3, 1, 1, 3, 3], [1, 3, 3, 3, 3, 3, 1, 1], [1, 3, 3, 3, 3, 1, 3, 1],\n",
    "                               [1, 3, 3, 3, 1, 3, 3, 1], [1, 3, 3, 3, 3, 1, 1, 3], [1, 3, 3, 3, 1, 3, 1, 3],\n",
    "                               [1, 1, 3, 3, 1, 3, 3, 3], [3, 3, 1, 1, 3, 3, 3, 1]]) / 2\n",
    "\n",
    "\n",
    "    return torch.cat([d8_half_vectors, additional], dim=0)\n",
    "\n",
    "\n",
    "def generate_d8_signs(d8_half_vectors:torch.Tensor)->torch.Tensor:\n",
    "        \"\"\"Generate the signs for the d8 half vectors.\"\"\"\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        for vec in d8_half_vectors:\n",
    "            for signs in product([-1, 1], repeat=7):\n",
    "                new_vec = vec.clone()\n",
    "                new_vec[1:] = new_vec[1:] * torch.tensor(signs)\n",
    "\n",
    "                if new_vec.sum() % 2 != 0:\n",
    "                    new_vec[0] = -new_vec[0]\n",
    "\n",
    "                if new_vec.sum() % 2 != 0:\n",
    "                    raise ValueError(\"Invalid vector\")\n",
    "\n",
    "                vectors.append(new_vec)\n",
    "\n",
    "        vectors = torch.stack(vectors, dim=0)\n",
    "\n",
    "        #assert vectors.shape[0] == 2 ** (7 + 8)\n",
    "\n",
    "        return vectors\n",
    "\n",
    "def add(d8_signs:torch.Tensor)->torch.Tensor:\n",
    "    return torch.cat([d8_signs, d8_signs + 0.25], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575b3617",
   "metadata": {},
   "outputs": [],
   "source": [
    "d8_full = append_12(d8)\n",
    "d8_signs = generate_d8_signs(d8_full)\n",
    "codebook = add(d8_signs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c198d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65536, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(codebook, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9d190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(product([-1, 1], repeat=7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05768a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**(7+8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe7835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** (7 + 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b20af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7876, 2.4469, 3.0478, 3.7594])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.load(\"codebook_magnitude.pt\")\n",
    "\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
